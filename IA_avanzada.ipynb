{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA-avanzada.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft4XsyBFf804",
        "colab_type": "text"
      },
      "source": [
        "# Visión general de la solución:\n",
        "\n",
        "**Nombres:**\n",
        " - Kelvin Ricardo Arrobo Castillo\n",
        " - Bruno Alexander Esparza Carchi\n",
        "\n",
        "La aplicación de conteo y reconocimiento de personas ha sido desarrollada sobre la API proporcionada por Tensorflow la cual nos ofrece múltiples alternativas fiables para lograr el objetivo de reconocer, dar seguimiento y contar personas.\n",
        "\n",
        "Se ha decidido utilizar un modelo previamente entrenado basado en SSD de MobileNet el cual nos provee un modelo confiable previamente entrenado, reduciendo la complejidad de cálculo computacional, esto es muy importante si tenemos en cuenta las características y especificaciones de los dispositivos en los cuales podremos correr la aplicación.\n",
        "\n",
        "## Instalación y Prerrequisitos\n",
        "\n",
        "Prerrequisitos:\n",
        "\n",
        "-   Python 3.5 a 3.7 ([descargar del sitio oficial](https://www.python.org/downloads/))\n",
        "    \n",
        "-   Tensorflow ([guia de instalación](https://www.tensorflow.org/install/))\n",
        "    \n",
        "\n",
        "### Proceso de instalación:\n",
        "\n",
        "Para realizar la instalación se debe descargar el codigo fuente del siguiente enlace: https://github.com/baesparza/tensorflow_object_counting_api/releases/tag/ia-avanzada\n",
        "\n",
        "Luego debemos subir el archivo al entorno virtual del colab para descomprimir el codigo fuente en colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUgeCBXQqFBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#==============================\n",
        "# Once the zipped source file has been loaded, \n",
        "# unzip the source files in the current directory\n",
        "#==============================\n",
        "\n",
        "!unzip /content/tensorflow_object_counting_api-ia-avanzada.zip\n",
        "\n",
        "!mv /content/tensorflow_object_counting_api-ia-avanzada/ /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvg95lpWsEr4",
        "colab_type": "text"
      },
      "source": [
        "Instalar las despendencias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqcMPrNjsD5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ornZ_0GFqBcg",
        "colab_type": "text"
      },
      "source": [
        "# Funcionamiento\n",
        "\n",
        "Primero se debe configurar en el archivo de configuracion  pedestrians_counting.py:\n",
        "\n",
        "En el configuramos la ruta del archivo de video esto para que la aplicación sepa de donde tomar el input para el procesamiento.\n",
        "```\n",
        "input_video = \"./video1.mp4\"\n",
        "```\n",
        "\n",
        "Posteriormente se configuran las variables, para que el programa se ajuste al video de input:\n",
        "\n",
        "-   ```is_color_recognition_enabled``` (feature de reconocimiento de color) 1 Si está activada, 0 si está desactivada.\n",
        "    \n",
        "-   ```roi``` (la posición del umbral de conteo) cualquier valor entero\n",
        "    \n",
        "-   ```deviation``` (el área de conteo del objeto) 1 o 0\n",
        "    \n",
        "-   ```axis``` (la orientación del umbral horizontal o vertical) x o y\n",
        "\n",
        "Una vez iniciada la aplicación empezará a realizar el procesamiento fotograma por fotograma hasta su terminación, dándonos como resultado el video con el reconocimiento y el conteo de las personas. este video se exportará en el directorio raíz del proyecto conjunto al log con los nombres ```the_output.avi``` y ```the_output.txt``` respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDNFnXlVbE1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_video = \"./video1.mp4\" #@param {type:\"string\"}\n",
        "axis = 'y' #@param [\"x\", \"y\"]\n",
        "roi = 250 #@param {type:\"number\"}\n",
        "\n",
        "#==============================\n",
        "# main\n",
        "#==============================\n",
        "\n",
        "from pedestrian_counting import run\n",
        "\n",
        "run(input_video, roi, axis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoRkkjZZa_vD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Resultados:\n",
        "\n",
        "![resultado](https://res.cloudinary.com/dmbe2ysrs/image/upload/v1594700657/ia/demo_yx1vz9.jpg)\n",
        "\n",
        " Haciendo la prueba con el video # 1 obtuvimos los siguientes resultados: \n",
        "\n",
        "|Conteo manual|Conteo automático|\n",
        "|----------|--------|\n",
        "|10 personas|6 personas|\n",
        "\n",
        "# Conclusiones:\n",
        "\n",
        "El resultado depende de la posición de las personas al cruzar el umbral, si estas se encuentran al mismo tiempo en el umbral solo contará como una sola por la superposición de las mismas, en esos casos una mejora podría ser tener videos de entrada de distintos ángulos para mejorar la precisión."
      ]
    }
  ]
}